# rtsp_motion_detector.py
import cv2
import csv
import os
import time
import json
import logging
import io
from ultralytics import YOLO
from bot.config import ADMIN_ID

# ===================== –ù–ê–°–¢–†–û–ô–ö–ò =====================
SENSITIVITY = 25
MIN_AREA = 800
PLAYBACK_SPEED = 8
SAVE_FRAMES = True
RECOGNITION_DELAY_SEC = 4
OUTPUT_FILE = "rtsp_motions_log.csv"
FRAMES_DIR = "rtsp_motion_frames"
YOLO_MODEL = "yolov8n.pt"
CONF_THRESHOLD = 0.7
TARGET_CLASSES = ["person", "cat", "dog"]

# –õ–æ–≥–≥–µ—Ä
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    handlers=[
        logging.FileHandler("motion_debug.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

os.makedirs(FRAMES_DIR, exist_ok=True)

# ===================== –£—Ç–∏–ª–∏—Ç—ã =====================
def now_ts():
    return time.strftime("%Y-%m-%d %H:%M:%S")

def date_dir():
    d = time.strftime("%Y%m%d")
    p = os.path.join(FRAMES_DIR, d)
    os.makedirs(p, exist_ok=True)
    return p

# ===================== YOLO =====================
logging.info("üì¶ –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å YOLOv8...")
model = YOLO(YOLO_MODEL)

if not os.path.exists(OUTPUT_FILE):
    with open(OUTPUT_FILE, "w", newline="", encoding="utf-8") as f:
        csv.writer(f).writerow(["camera", "timestamp", "class", "confidence"])

# ===================== –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è =====================
async def run_rtsp_detector(bot, enabled_flag: callable):
    """
    bot          - —ç–∫–∑–µ–º–ø–ª—è—Ä telegram.Bot
    enabled_flag - —Ñ—É–Ω–∫—Ü–∏—è/–ª—è–º–±–¥–∞, –∫–æ—Ç–æ—Ä–∞—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True/False (–≤–∫–ª/–≤—ã–∫–ª –∞–Ω–∞–ª–∏–∑)
    """

    with open("cameras.json", "r", encoding="utf-8") as c:
        cameras = json.load(c)
    if not cameras:
        logging.error("‚ùå cameras.json –ø—É—Å—Ç–æ–π.")
        return

    logging.info(f"üîç –ö–∞–º–µ—Ä: {len(cameras)}. –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞...")

    for name, url in cameras.items():
        # –∫–∞–∂–¥–∞—è –∫–∞–º–µ—Ä–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ async –Ω–µ –¥–µ–ª–∞–µ–º ‚Äî –ø–æ–π–¥—ë–º –ø–æ –æ—á–µ—Ä–µ–¥–∏
        await detect_motion_and_objects(bot, name, url, enabled_flag)


async def detect_motion_and_objects(bot, camera_name, rtsp_url, enabled_flag):
    try:
        cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
        if not cap.isOpened():
            logging.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ {camera_name}")
            return

        ret, frame1 = cap.read()
        ret2, frame2 = cap.read()
        if not ret or not ret2:
            cap.release()
            return

        last_trigger_time = 0.0
        frame_count = 0

        while True:
            if not enabled_flag():
                await bot.send_message(chat_id=ADMIN_ID, text="‚èπ –î–µ—Ç–µ–∫—Ç–æ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                break

            if frame_count % PLAYBACK_SPEED != 0:
                frame1 = frame2
                if not cap.grab():
                    break
                ok, frame2 = cap.retrieve()
                if not ok:
                    break
                frame_count += 1
                continue

            small1 = cv2.resize(frame1, (640, 360))
            small2 = cv2.resize(frame2, (640, 360))
            diff = cv2.absdiff(small1, small2)
            gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
            blur = cv2.GaussianBlur(gray, (5, 5), 0)
            _, thresh = cv2.threshold(blur, SENSITIVITY, 255, cv2.THRESH_BINARY)
            dilated = cv2.dilate(thresh, None, iterations=3)
            contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
            motion_detected = any(cv2.contourArea(c) >= MIN_AREA for c in contours)

            if motion_detected:
                results = model(frame2, verbose=False)[0]
                for box in results.boxes:
                    cls_id = int(box.cls[0])
                    class_name = results.names[cls_id]
                    conf = float(box.conf[0])

                    if class_name in TARGET_CLASSES and conf >= CONF_THRESHOLD:
                        now = time.time()
                        if (now - last_trigger_time) >= RECOGNITION_DELAY_SEC:
                            ts = now_ts()
                            logging.info(f"‚úÖ {camera_name}: {class_name} ({conf:.2f}), {ts}")

                            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–¥—Ä –∞–¥–º–∏–Ω—É
                            _, buf = cv2.imencode(".jpg", frame2)
                            image_bytes = io.BytesIO(buf)
                            await bot.send_photo(
                                chat_id=ADMIN_ID,
                                photo=image_bytes,
                                caption=f"{camera_name}: {class_name} ({conf:.2f}) {ts}"
                            )

                            if SAVE_FRAMES:
                                fname = f"{camera_name}_{ts.replace(':', '-')}_{class_name}.jpg"
                                cv2.imwrite(os.path.join(date_dir(), fname), frame2)

                            with open(OUTPUT_FILE, "a", newline="", encoding="utf-8") as f:
                                csv.writer(f).writerow([camera_name, ts, class_name, f"{conf:.2f}"])

                            last_trigger_time = now
                        break

            frame1 = frame2
            if not cap.grab():
                break
            ok, frame2 = cap.retrieve()
            if not ok:
                break
            frame_count += 1

        cap.release()

    except Exception as e:
        logging.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {camera_name}: {e}")
